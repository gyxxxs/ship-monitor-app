import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import time
from datetime import datetime
from google import genai
from google.genai import types
from pydantic import BaseModel, Field
import json

# --- 0. ç¯å¢ƒå’Œå·¥å…·å®šä¹‰ ---

class ReportInput(BaseModel):
    """ç”¨äºç”Ÿæˆè¯¦ç»†æ•…éšœè¯Šæ–­æŠ¥å‘Šçš„å·¥å…·"""
    fault_id: str = Field(description="å½“å‰æ•…éšœäº‹ä»¶çš„å”¯ä¸€æ ‡è¯†IDï¼Œä¾‹å¦‚ï¼š'EVENT-20251028-001'")
    severity: str = Field(description="æ•…éšœçš„ä¸¥é‡ç¨‹åº¦ï¼Œä¾‹å¦‚ï¼š'ä¸€çº§é¢„è­¦'æˆ–'äºŒçº§é¢„è­¦'")
    fault_type: str = Field(description="æ•…éšœç±»å‹ï¼Œå¦‚ï¼š'ä¸²è”ç”µå¼§æ•…éšœ'ã€'ç»ç¼˜è€åŒ–'ç­‰")

class StabilityInput(BaseModel):
    """ç”¨äºæŸ¥è¯¢èˆ¹ç«¯è¾¹ç¼˜è®¡ç®—å•å…ƒå’Œèˆ¹å²¸ååŒé€šä¿¡é“¾è·¯çš„å®æ—¶çŠ¶æ€å’Œè´Ÿè½½ç‡"""

class MaintenanceInput(BaseModel):
    """æ ¹æ®æ•…éšœç±»å‹ç”Ÿæˆç»´æŠ¤å·¥å•"""
    circuit_id: str = Field(description="å›è·¯ç¼–å·ï¼Œä¾‹å¦‚ï¼š'03å·èˆ±å›è·¯'")
    fault_severity: str = Field(description="æ•…éšœä¸¥é‡ç¨‹åº¦")
    maintenance_type: str = Field(description="ç»´æŠ¤ç±»å‹ï¼šé¢„é˜²æ€§/ç´§æ€¥")

def generate_diagnostic_report(fault_id: str, severity: str, fault_type: str) -> str:
    """ç”Ÿæˆæ ¼å¼åŒ–çš„æ•…éšœè¯Šæ–­æŠ¥å‘Š"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_data = {
        "report_id": f"RPT-{fault_id}",
        "timestamp": timestamp,
        "fault_severity": severity,
        "fault_type": fault_type,
        "dl_confidence": "97.5%",
        "root_cause": "é«˜æŒ¯åŠ¨åŒºåŸŸç”µç¼†å›ºå®šä»¶è€åŒ–æ¾åŠ¨å¯¼è‡´çš„ä¸²è”ç”µå¼§æ•…éšœ",
        "maintenance_advice": "ç«‹å³è¿›è¡Œé¢„é˜²æ€§æ£€æŸ¥ï¼Œç´§å›ºè¿æ¥ä»¶ï¼Œå‚è€ƒCCSè§„èŒƒç¬¬5.4.1æ¡",
        "risk_level": "é«˜" if "äºŒçº§" in severity else "ä¸­"
    }
    return f"ã€è¯Šæ–­æŠ¥å‘Šã€‘{json.dumps(report_data, ensure_ascii=False, indent=2)}"

def check_system_stability() -> str:
    """æŸ¥è¯¢ç³»ç»Ÿç¨³å®šæ€§çŠ¶æ€"""
    stability_data = {
        "edge_compute_load": "38%",
        "inference_latency": "15ms", 
        "communication_latency": "45ms",
        "model_accuracy": "97.5%",
        "system_status": "ç¨³å®š"
    }
    return f"ã€ç³»ç»ŸçŠ¶æ€ã€‘{json.dumps(stability_data, ensure_ascii=False)}"

def generate_maintenance_order(circuit_id: str, fault_severity: str, maintenance_type: str) -> str:
    """ç”Ÿæˆç»´æŠ¤å·¥å•"""
    order_data = {
        "order_id": f"MO-{datetime.now().strftime('%Y%m%d%H%M')}",
        "circuit": circuit_id,
        "maintenance_type": maintenance_type,
        "priority": "ç´§æ€¥" if "äºŒçº§" in fault_severity else "é«˜",
        "required_tools": "çº¢å¤–çƒ­åƒä»ª,åŠ›çŸ©æ‰³æ‰‹,ç»ç¼˜æµ‹è¯•ä»ª",
        "estimated_duration": "2å°æ—¶",
        "safety_requirements": "æ–­ç”µæ“ä½œï¼Œç©¿æˆ´PPE"
    }
    return f"ã€ç»´æŠ¤å·¥å•ã€‘{json.dumps(order_data, ensure_ascii=False)}"

AVAILABLE_TOOLS = {
    "generate_diagnostic_report": generate_diagnostic_report,
    "check_system_stability": check_system_stability,
    "generate_maintenance_order": generate_maintenance_order,
}

# --- 1. å¢å¼ºçš„æ•°æ®æ¨¡æ‹Ÿ ---
def simulate_current_data(t, fault_scenario="normal", prediction_mode=False):
    """
    æ¨¡æ‹Ÿæ›´çœŸå®çš„èˆ¹èˆ¶ç”µæµæ•°æ®
    fault_scenario: 'normal', 'early_arc', 'severe_arc', 'motor_start'
    """
    base_frequency = 50
    time_series = np.linspace(0, 2 / base_frequency, t)  # 2ä¸ªå‘¨æœŸ
    current = 10 * np.sin(2 * np.pi * base_frequency * time_series)
    
    # åŸºç¡€å™ªå£°
    current += np.random.normal(0, 0.05, t)
    
    if fault_scenario == "early_arc":
        # æ—©æœŸç”µå¼§ç‰¹å¾ï¼šé—´æ­‡æ€§é«˜é¢‘å™ªå£°
        mask = (time_series % 0.1 < 0.02)  # 10%æ—¶é—´å‡ºç°ç”µå¼§
        high_freq = np.sin(2 * np.pi * 5000 * time_series) * 0.3
        current += high_freq * mask
        
    elif fault_scenario == "severe_arc":
        # ä¸¥é‡ç”µå¼§ç‰¹å¾ï¼šæŒç»­é«˜é¢‘å™ªå£°+å¹…å€¼å˜åŒ–
        high_freq = np.sin(2 * np.pi * 3000 * time_series) * 0.8
        current += high_freq + 2 * np.random.rand(t)
        
    elif fault_scenario == "motor_start":
        # ç”µæœºå¯åŠ¨å¹²æ‰°
        startup_effect = 3 * np.exp(-time_series * 2) * np.sin(2 * np.pi * 100 * time_series)
        current += startup_effect

    if prediction_mode:
        # é¢„æµ‹æ¨¡å¼ä¸‹çš„è¶‹åŠ¿ç‰¹å¾
        trend = 0.5 * np.exp(-time_series * 3) * np.sin(2 * np.pi * 150 * time_series)
        current += trend

    return time_series * 1000, current

# --- 2. å¢å¼ºçš„æ¨¡å‹æ¨ç†æ¨¡æ‹Ÿ ---
def dl_model_inference(data, fault_scenario):
    """æ¨¡æ‹ŸåŒé‡æ·±åº¦å­¦ä¹ å¼•æ“çš„æ¨ç†ç»“æœ"""
    
    # 1D-DSTN/1D-DITN æ£€æµ‹ç»“æœ
    max_current = np.max(np.abs(data))
    high_freq_energy = np.std(data - np.mean(data))
    
    if fault_scenario == "severe_arc":
        return "äºŒçº§é¢„è­¦ (æ•…éšœç¡®è®¤)", 97.5, "severe_arc"
    elif fault_scenario == "early_arc":
        if high_freq_energy > 0.4:
            return "ä¸€çº§é¢„è­¦ (é¢„æµ‹é£é™©)", 85.0, "early_arc"
        else:
            return "è¿è¡Œæ­£å¸¸ (å®‰å…¨)", 5.0, "normal"
    elif fault_scenario == "motor_start":
        return "å¹²æ‰°ä¿¡å· (ç”µæœºå¯åŠ¨)", 10.0, "motor_start"
    else:
        return "è¿è¡Œæ­£å¸¸ (å®‰å…¨)", 2.0, "normal"

# --- 3. æ™ºèƒ½ä½“æ ¸å¿ƒé€»è¾‘ ---
@st.cache_resource
def get_gemini_client():
    """å®‰å…¨åœ°è·å– Gemini å®¢æˆ·ç«¯"""
    try:
        GEMINI_API_KEY = st.secrets["gemini_api_key"]
        return genai.Client(api_key=GEMINI_API_KEY)
    except KeyError:
        st.error("åˆå§‹åŒ–å¤±è´¥ï¼šæ— æ³•æ‰¾åˆ° Gemini API å¯†é’¥ã€‚è¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­é…ç½® 'gemini_api_key'ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯å¤±è´¥: {e}")
        st.stop()

def gemini_agent_response(user_query: str, system_status: dict):
    """å¢å¼ºçš„æ™ºèƒ½ä½“å“åº”å‡½æ•°"""
    client = get_gemini_client()
    
    # æ„å»ºç³»ç»ŸçŠ¶æ€ä¸Šä¸‹æ–‡
    status_context = (
        f"ã€å®æ—¶ç³»ç»ŸçŠ¶æ€ã€‘\n"
        f"- æ£€æµ‹çŠ¶æ€: {system_status['detection_status']}\n"
        f"- ç½®ä¿¡åº¦: {system_status['confidence']}%\n" 
        f"- æ•…éšœç±»å‹: {system_status['fault_type']}\n"
        f"- å›è·¯ç¼–å·: {system_status['circuit_id']}\n"
        f"- æ—¶é—´æˆ³: {system_status['timestamp']}\n"
    )
    
    GROUNDING_FACTS = (
        "ã€RAGæ£€ç´¢ç»“æœï¼šèˆ¹èˆ¶ç”µæ°”å®‰å…¨çŸ¥è¯†åº“ç²¾è¦ã€‘\n"
        "--- 1. é¢„æµ‹ä¸é¢„è­¦ï¼ˆåŸºäº Informer æ¨¡å‹ï¼‰---\n"
        " - **ä¸€çº§é¢„è­¦ç‰¹å¾**ï¼šç”µæµæ³¢å½¢å‘ˆç°ä¸è§„åˆ™é«˜é¢‘éœ‡è¡ï¼ˆ1-5kHzï¼‰ï¼Œå¹…å€¼å˜åŒ–Â±15%ï¼Œè¿™æ˜¯æ—©æœŸç”µå¼§çš„æ˜ç¡®ä¿¡å·ã€‚\n"
        " - **äºŒçº§é¢„è­¦ç‰¹å¾**ï¼šæŒç»­é«˜é¢‘å™ªå£°ï¼ˆ3-8kHzï¼‰ï¼Œç”µæµå¹…å€¼å¼‚å¸¸æ³¢åŠ¨è¶…è¿‡Â±30%ï¼Œéœ€ç«‹å³å¤„ç†ã€‚\n"
        "--- 2. æ•…éšœè¯Šæ–­ï¼ˆå†å²ç»éªŒå½’å› ï¼‰---\n"
        " - **æ ¹æœ¬åŸå› **ï¼š80%çš„èˆ¹èˆ¶ç”µå¼§æ•…éšœæºäºé«˜æŒ¯åŠ¨åŒºåŸŸçš„ç”µç¼†è¿æ¥ç‚¹æ¥è§¦ä¸è‰¯ã€‚\n"
        " - **å…¸å‹ä½ç½®**ï¼šæœºèˆ±ã€è´§èˆ±æ³µåŒºã€ç”²æ¿æœºæ¢°ä¾›ç”µå›è·¯ã€‚\n"
        "--- 3. ç»´æŠ¤è§„èŒƒï¼ˆèˆ¹çº§ç¤¾è¦æ±‚ï¼‰---\n"
        " - **CCSè§„èŒƒç¬¬5.4.1æ¡**ï¼šé«˜æŒ¯åŠ¨åŒºåŸŸæ¯å­£åº¦å¿…é¡»è¿›è¡Œé¢„é˜²æ€§æ£€æŸ¥å’Œç´§å›ºç»´æŠ¤ã€‚\n"
        " - **ABSè§„èŒƒç¬¬4-8-3æ¡**ï¼šæ£€æµ‹åˆ°ç”µå¼§æ•…éšœåï¼Œéœ€åœ¨24å°æ—¶å†…å®Œæˆæ ¹æœ¬åŸå› åˆ†æã€‚\n"
    )

    system_instruction = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èˆ¹èˆ¶ç”µæ°”å®‰å…¨æ™ºèƒ½ä½“ï¼ŒåŸºäºèˆ¹å²¸ååŒæ¶æ„å·¥ä½œã€‚"
        "ä½ å¿…é¡»ç»“åˆå®æ—¶ç³»ç»ŸçŠ¶æ€ã€RAGçŸ¥è¯†åº“å’Œå¯ç”¨å·¥å…·æ¥æä¾›å‡†ç¡®çš„è¯Šæ–­å’Œå»ºè®®ã€‚"
        "å¯¹äºé¢„è­¦ä¿¡æ¯ï¼Œè¦æ˜ç¡®è¯´æ˜é£é™©ç­‰çº§å’Œåº”å¯¹æªæ–½ï¼›å¯¹äºæ•…éšœè¯Šæ–­ï¼Œè¦å¼•ç”¨ç›¸å…³è§„èŒƒæ¡æ¬¾ã€‚"
        f"å½“å‰ç³»ç»ŸçŠ¶æ€ï¼š{status_context}"
    )
    
    full_prompt = system_instruction + "\n\n" + GROUNDING_FACTS + "\n\nç”¨æˆ·æé—®ï¼š" + user_query

    try:
        config = types.GenerateContentConfig(
            system_instruction=system_instruction,
            tools=list(AVAILABLE_TOOLS.values()),
        )
        
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=full_prompt,
            config=config,
        )
        
        if response.function_calls:
            for function_call in response.function_calls:
                tool_name = function_call.name
                tool_args = dict(function_call.args)
                
                if tool_name in AVAILABLE_TOOLS:
                    tool_result = AVAILABLE_TOOLS[tool_name](**tool_args)
                    
                    response_after_tool = client.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=[
                            types.Content(role="user", parts=[types.Part.from_text(full_prompt)]),
                            types.Content(role="model", parts=[types.Part.from_function_call(function_call)]),
                            types.Content(role="tool", parts=[types.Part.from_text(tool_result)]),
                        ],
                        config=types.GenerateContentConfig(system_instruction=system_instruction),
                    )
                    return response_after_tool.text 
                
        return response.text

    except Exception as e:
        return f"æ™ºèƒ½ä½“ API è°ƒç”¨å¤±è´¥ã€‚é”™è¯¯ä¿¡æ¯: {e}"

# --- 4. ä¸»ç•Œé¢ ---
def main():
    st.set_page_config(layout="wide", page_title="èˆ¹èˆ¶æ•…éšœç”µå¼§æ™ºèƒ½ç›‘æµ‹ä¸é¢„è­¦å¹³å°")
    st.title("ğŸš¢ èˆ¹èˆ¶æ•…éšœç”µå¼§æ™ºèƒ½ç›‘æµ‹ä¸é¢„è­¦å¹³å°")
    st.markdown("**èˆ¹å²¸ååŒæ¶æ„ | åŒé‡æ·±åº¦å­¦ä¹ å¼•æ“ | å¤§æ¨¡å‹æ™ºèƒ½ä½“èµ‹èƒ½**")

    # åˆå§‹åŒ–çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'fault_scenario' not in st.session_state:
        st.session_state.fault_scenario = "normal"
    if 'circuit_id' not in st.session_state:
        st.session_state.circuit_id = "03å·èˆ±å›è·¯"
    if 'last_update' not in st.session_state:
        st.session_state.last_update = time.time()

    # æ£€æŸ¥å¯†é’¥
    get_gemini_client()

    # ä¾§è¾¹æ  - ç³»ç»Ÿé…ç½®
    with st.sidebar:
        st.header("ç³»ç»Ÿé…ç½®")
        st.session_state.circuit_id = st.selectbox(
            "ç›‘æµ‹å›è·¯",
            ["03å·èˆ±å›è·¯", "æœºèˆ±ä¸»é…ç”µæ¿", "è´§èˆ±æ³µå›è·¯", "å¯¼èˆªè®¾å¤‡ä¾›ç”µ"]
        )
        
        st.subheader("æ•…éšœåœºæ™¯æ¨¡æ‹Ÿ")
        scenario = st.radio(
            "é€‰æ‹©è¿è¡Œæ¨¡å¼:",
            ["æ­£å¸¸è¿è¡Œ", "æ—©æœŸç”µå¼§é¢„è­¦", "ä¸¥é‡ç”µå¼§æ•…éšœ", "ç”µæœºå¯åŠ¨å¹²æ‰°"]
        )
        
        scenario_map = {
            "æ­£å¸¸è¿è¡Œ": "normal",
            "æ—©æœŸç”µå¼§é¢„è­¦": "early_arc", 
            "ä¸¥é‡ç”µå¼§æ•…éšœ": "severe_arc",
            "ç”µæœºå¯åŠ¨å¹²æ‰°": "motor_start"
        }
        st.session_state.fault_scenario = scenario_map[scenario]
        
        # ç³»ç»Ÿä¿¡æ¯
        st.subheader("ç³»ç»Ÿä¿¡æ¯")
        st.info("""
        **æ¶æ„å±‚çº§:**
        - ğŸš¢ èˆ¹ç«¯è¾¹ç¼˜è®¡ç®—
        - â˜ï¸ å²¸åŸºæ™ºèƒ½ä½“
        - ğŸ”— èˆ¹å²¸ååŒ
        """)

    col1, col2 = st.columns([3, 2])

    with col1:
        st.header("ğŸ“Š å®æ—¶ç›‘æµ‹ Dashboard")
        
        # å®æ—¶æ•°æ®ç”Ÿæˆ
        t_series, current_data = simulate_current_data(
            t=4000, 
            fault_scenario=st.session_state.fault_scenario,
            prediction_mode=(st.session_state.fault_scenario == "early_arc")
        )
        
        # æ¨¡å‹æ¨ç†
        status_text, confidence, fault_type = dl_model_inference(
            current_data, st.session_state.fault_scenario
        )
        
        # ç³»ç»ŸçŠ¶æ€
        system_status = {
            "detection_status": status_text,
            "confidence": confidence,
            "fault_type": fault_type,
            "circuit_id": st.session_state.circuit_id,
            "timestamp": datetime.now().strftime("%H:%M:%S")
        }
        
        # çŠ¶æ€æ˜¾ç¤º
        status_color = {
            "è¿è¡Œæ­£å¸¸": "green",
            "å¹²æ‰°ä¿¡å·": "blue", 
            "ä¸€çº§é¢„è­¦": "orange",
            "äºŒçº§é¢„è­¦": "red"
        }
        
        color = "green"
        for key, value in status_color.items():
            if key in status_text:
                color = value
                break
                
        st.markdown(
            f"**æ£€æµ‹çŠ¶æ€:** <span style='color:{color}; font-size: 24px;'>{status_text}</span>",
            unsafe_allow_html=True
        )
        st.metric("æ¨¡å‹ç½®ä¿¡åº¦", f"{confidence:.1f}%")
        st.metric("ç›‘æµ‹å›è·¯", st.session_state.circuit_id)
        
        # æ³¢å½¢å›¾
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(t_series, current_data, label='ç”µæµæ³¢å½¢ (A)', color=color, linewidth=1)
        ax.set_title(f"å®æ—¶ç”µæµæ³¢å½¢ç›‘æµ‹ - {st.session_state.circuit_id}")
        ax.set_xlabel("æ—¶é—´ (ms)")
        ax.set_ylabel("ç”µæµ (A)")
        ax.grid(True, linestyle='--', alpha=0.6)
        ax.set_ylim(-20, 20)
        ax.legend()
        st.pyplot(fig)
        plt.close(fig)
        
        # é¢‘è°±åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
        if "é¢„è­¦" in status_text:
            st.warning("ğŸ” æ£€æµ‹åˆ°é«˜é¢‘å™ªå£°æˆåˆ†ï¼Œå»ºè®®è¿›è¡Œè¯¦ç»†é¢‘è°±åˆ†æ")

    with col2:
        st.header("ğŸ’¬ æ™ºèƒ½ä½“äº¤äº’ä¸­å¿ƒ")
        
        # æ˜¾ç¤ºå†å²æ¶ˆæ¯
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # é¢„è®¾é—®é¢˜
        st.subheader("ğŸ’¡ é¢„è®¾é—®é¢˜")
        presets = {
            "å‰ç»é¢„è­¦": "å½“å‰æ³¢å½¢èµ°åŠ¿æ˜¯å¦æ­£å¸¸ï¼Ÿæœ‰æ— æ½œåœ¨çš„ç”µå¼§é£é™©ï¼Ÿ",
            "è¯Šæ–­æŸ¥è¯¢": "è¯·åˆ†ææ•…éšœæ ¹æœ¬åŸå› å’Œèˆ¹çº§ç¤¾ç»´æŠ¤è¦æ±‚",
            "ç³»ç»ŸçŠ¶æ€": "è¾¹ç¼˜è®¡ç®—å•å…ƒå’Œé€šä¿¡é“¾è·¯çŠ¶æ€å¦‚ä½•ï¼Ÿ",
            "ç»´æŠ¤æŒ‡å¯¼": "æ ¹æ®å½“å‰é¢„è­¦ç”Ÿæˆç»´æŠ¤å·¥å•"
        }
        
        for preset_name, preset_text in presets.items():
            if st.button(f"{preset_name}: {preset_text}", key=preset_name):
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": preset_text})
                with st.chat_message("user"):
                    st.markdown(preset_text)

                # ç”Ÿæˆæ™ºèƒ½ä½“å“åº”
                with st.chat_message("assistant"):
                    with st.spinner("æ™ºèƒ½ä½“æ¨ç†ä¸­..."):
                        response = gemini_agent_response(preset_text, system_status)
                    
                    # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                    full_response = ""
                    message_placeholder = st.empty()
                    for chunk in response.split():
                        full_response += chunk + " "
                        time.sleep(0.01)
                        message_placeholder.markdown(full_response + "â–Œ")
                    message_placeholder.markdown(full_response)
                    
                # ä¿å­˜æ™ºèƒ½ä½“å“åº”
                st.session_state.messages.append({"role": "assistant", "content": response})
                st.rerun()
        
        # èŠå¤©è¾“å…¥
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("æ™ºèƒ½ä½“æ¨ç†ä¸­..."):
                    response = gemini_agent_response(prompt, system_status)
                
                full_response = ""
                message_placeholder = st.empty()
                for chunk in response.split():
                    full_response += chunk + " "
                    time.sleep(0.01)
                    message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
                
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.rerun()

if __name__ == "__main__":
    main()
