import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import time


# --- 1. æ•°æ®æ¨¡æ‹Ÿ ---
def simulate_current_data(t, is_fault, prediction_mode=False):
    base_frequency = 50
    time_series = np.linspace(0, 1 / base_frequency, t)
    current = 10 * np.sin(2 * np.pi * base_frequency * time_series) + np.random.normal(0, 0.1, t)

    if is_fault:
        high_freq_noise = np.sin(2 * np.pi * 5000 * time_series) * 0.5 * np.random.rand(t)
        arc_pulse = np.maximum(0, np.sin(2 * np.pi * 50 * time_series) - 0.5) * 5
        current += high_freq_noise * arc_pulse

    if prediction_mode:
        current += 0.5 * np.exp(-time_series * 5) * np.sin(2 * np.pi * 200 * time_series)

    return time_series * 1000, current


# --- 2. æ¨¡å‹æ¨ç†æ¨¡æ‹Ÿ ---
def dl_model_inference(data):
    if data.max() > 14 or data.min() < -14:
        return "äºŒçº§é¢„è­¦ (æ•…éšœç¡®è®¤)", 97.5
    elif data.max() > 12 or data.min() < -12:
        return "ä¸€çº§é¢„è­¦ (é¢„æµ‹é£é™©)", 75.0
    else:
        return "è¿è¡Œæ­£å¸¸ (å®‰å…¨)", 5.0


# --- 3. æ™ºèƒ½ä½“é€»è¾‘ ---
def intelligent_agent_response(user_query, current_status):
    query = user_query.lower()
    if any(k in query for k in ["æ³¢å½¢èµ°åŠ¿", "é¢„æµ‹", "æ½œåœ¨é£é™©"]):
        if "ä¸€çº§é¢„è­¦" in current_status:
            return (
                "**[æ—¶åºé¢„æµ‹ç»“æœ]**ï¼šç»åŸºäº**Informerç½‘ç»œ**çš„æ¨¡å‹åˆ†æï¼Œé¢„æµ‹ç”µæµæ³¢å½¢èµ°åŠ¿å°†å‘ˆç°**æŒç»­æ¶åŒ–çš„ä¸è§„åˆ™é«˜é¢‘éœ‡è¡**ï¼Œç¬¦åˆä¸€çº§ï¼ˆæ—©æœŸï¼‰ä¸²è”æ•…éšœç”µå¼§çš„èµ·å§‹ç‰¹å¾ã€‚\n\n"
                "**[å¤„ç½®å»ºè®®]**ï¼šè¯·èˆ¹å‘˜ç«‹å³æ£€æŸ¥è¯¥å›è·¯è´Ÿè½½ç«¯å£çš„æ¸©åº¦å¼‚å¸¸ï¼Œå¹¶å‡†å¤‡é¢„é˜²æ€§ç»´æŠ¤å·¥å•ï¼Œç­‰å¾…è¿›ä¸€æ­¥æŒ‡ç¤ºã€‚å·²åŒæ­¥å²¸åŸºè¿ç»´ä¸­å¿ƒã€‚"
            )
        else:
            return "å½“å‰æ³¢å½¢èµ°åŠ¿ç¨³å®šï¼Œæœªæ£€æµ‹åˆ°æ—©æœŸæ•…éšœç”µå¼§çš„é¢„æµ‹ç‰¹å¾ï¼Œç³»ç»Ÿè¿è¡Œå¹³ç¨³ã€‚"
    elif any(k in query for k in ["è§„èŒƒ", "ç»´æŠ¤è¦æ±‚", "æ ¹æœ¬åŸå› "]):
        return (
            "**[è¯Šæ–­åˆ†æ]**ï¼šå†å²æ•°æ®æ˜¾ç¤ºï¼Œè¯¥ç±»æ•…éšœä¸»è¦åŸå› ä¸ºé«˜æŒ¯åŠ¨åŒºåŸŸçš„**ç”µç¼†å›ºå®šä»¶è€åŒ–æ¾åŠ¨**ï¼Œå¯¼è‡´æ¥å¤´é˜»æŠ—å¢åŠ å¹¶äº§ç”Ÿé—´æ­‡æ€§æ”¾ç”µã€‚\n\n"
            "**[è§„èŒƒæŸ¥è¯¢]**ï¼šæ ¹æ®**[RAGçŸ¥è¯†åº“]**ï¼Œèˆ¹çº§ç¤¾è§„èŒƒ[XX-2023]ç¬¬5.4.1æ¡è¦æ±‚ï¼šå¯¹äºé«˜æŒ¯åŠ¨åŒºåŸŸçš„ç”µæ°”è¿æ¥ç‚¹ï¼Œåº”æ¯å­£åº¦è¿›è¡Œé¢„é˜²æ€§æ£€æŸ¥ã€‚\n\n"
            "**[å·¥å…·è°ƒç”¨]**ï¼šå·²è‡ªåŠ¨ç”Ÿæˆå¹¶å‘é€**ã€Šé«˜é£é™©éƒ¨ä»¶æ£€æŸ¥æŒ‡å¯¼æ‰‹å†Œã€‹**è‡³æ‚¨çš„å·¥ä½œç»ˆç«¯ã€‚"
        )
    elif any(k in query for k in ["ç¨³å®šæ€§", "è´Ÿè½½ç‡", "ç³»ç»ŸçŠ¶æ€"]):
        return (
            "**[ç³»ç»ŸçŠ¶æ€]**ï¼šèˆ¹ç«¯è¾¹ç¼˜è®¡ç®—å•å…ƒå½“å‰è´Ÿè½½ç‡ç¨³å®šåœ¨38%ï¼Œæ¨¡å‹æ¨ç†å»¶è¿Ÿåœ¨15msä»¥å†…ï¼Œ**ç¨³å®šæ€§è‰¯å¥½**ã€‚èˆ¹å²¸ååŒé€šä¿¡é“¾è·¯å»¶è¿Ÿä½äº50msï¼ŒçŠ¶æ€ç¨³å®šã€‚"
        )
    else:
        return f"æ‚¨å¥½ï¼Œæˆ‘æ˜¯èˆ¹èˆ¶å®‰å…¨æ™ºèƒ½ä½“ï¼Œå½“å‰ç³»ç»ŸçŠ¶æ€ä¸ºï¼š**{current_status}**ã€‚è¯·é—®æ‚¨éœ€è¦è¿›è¡Œæ•…éšœè¯Šæ–­ã€å®‰å…¨è§„èŒƒæŸ¥è¯¢ï¼Œè¿˜æ˜¯ç³»ç»ŸçŠ¶æ€æ£€æŸ¥ï¼Ÿ"


# --- 4. ä¸»ç•Œé¢ ---
def main():
    st.set_page_config(layout="wide", page_title="èˆ¹èˆ¶æ•…éšœç”µå¼§æ™ºèƒ½ç›‘æµ‹ä¸é¢„è­¦å¹³å°")
    st.title("ğŸš¢ èˆ¹èˆ¶æ•…éšœç”µå¼§æ™ºèƒ½ç›‘æµ‹ä¸é¢„è­¦å¹³å° (æ¼”ç¤ºåŸå‹)")

    # åˆå§‹åŒ–çŠ¶æ€ï¼ˆç¡®ä¿èŠå¤©è®°å½•ä¸ä¼šå› åˆ·æ–°ä¸¢å¤±ï¼‰
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'is_fault_active' not in st.session_state:
        st.session_state.is_fault_active = False
    if 't_start' not in st.session_state:
        st.session_state.t_start = time.time()
    # æ–°å¢ï¼šæ§åˆ¶åˆ·æ–°çš„æ ‡è®°
    if 'refresh_counter' not in st.session_state:
        st.session_state.refresh_counter = 0

    col1, col2 = st.columns([3, 2])

    with col1:
        st.header("å®æ—¶ç›‘æµ‹ä¸é¢„è­¦ Dashboard (èˆ¹ç«¯è¾¹ç¼˜è®¡ç®—æ¨¡æ‹Ÿ)")

        # æ•…éšœåˆ‡æ¢æŒ‰é’®ï¼ˆç”¨å›è°ƒæ›´æ–°çŠ¶æ€ï¼‰
        def toggle_fault():
            st.session_state.is_fault_active = not st.session_state.is_fault_active
            st.session_state.t_start = time.time()
        st.button(
            "ğŸ”´ æ¨¡æ‹Ÿæ•…éšœç”µå¼§å‘ç”Ÿ / ğŸŸ¢ æ¢å¤æ­£å¸¸è¿è¡Œ",
            on_click=toggle_fault
        )

        # ç”Ÿæˆå®æ—¶æ•°æ®
        t_series, current_data = simulate_current_data(
            t=2000,
            is_fault=st.session_state.is_fault_active,
            prediction_mode=(time.time() - st.session_state.t_start < 20 and not st.session_state.is_fault_active)
        )
        status_text, confidence = dl_model_inference(current_data)

        # æ˜¾ç¤ºçŠ¶æ€
        color = "green"
        if "ä¸€çº§é¢„è­¦" in status_text:
            color = "orange"
        elif "äºŒçº§é¢„è­¦" in status_text:
            color = "red"
        st.markdown(
            f"**æ¨¡å‹æ£€æµ‹çŠ¶æ€:** <span style='color:{color}; font-size: 20px;'>{status_text}</span> | **ç½®ä¿¡åº¦:** {confidence:.1f}%",
            unsafe_allow_html=True
        )

        # ç»˜åˆ¶æ³¢å½¢å›¾
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.plot(t_series, current_data, label='ç”µæµæ³¢å½¢ (A)', color=color)
        ax.set_title("å®æ—¶ç”µæµæ³¢å½¢ç›‘æµ‹ (èˆ¹ç«¯)")
        ax.set_xlabel("æ—¶é—´ (ms)")
        ax.set_ylabel("ç”µæµ (A)")
        ax.grid(True, linestyle='--', alpha=0.6)
        ax.set_ylim(-15, 15)
        st.pyplot(fig)
        plt.close(fig)

    with col2:
        st.header("æ™ºèƒ½ä½“äº¤äº’ä¸­å¿ƒ (å²¸åŸºè¿ç»´ä¸­å¿ƒæ¨¡æ‹Ÿ)")

        # æ˜¾ç¤ºå†å²æ¶ˆæ¯ï¼ˆä»session_stateè¯»å–ï¼Œç¡®ä¿åˆ·æ–°åä¸ä¸¢å¤±ï¼‰
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # é¢„è®¾å¯¹è¯å¼•å¯¼
        st.subheader("ğŸ’¡ é¢„è®¾æ¼”ç¤ºå¯¹è¯ (è¯·æ‰‹åŠ¨è¾“å…¥)")
        st.info("1. **å‰ç»é¢„è­¦**: è¯·é—®å½“å‰æ³¢å½¢èµ°åŠ¿æ˜¯å¦æ­£å¸¸ï¼Ÿæœ‰æ— æ½œåœ¨çš„ç”µå¼§é£é™©ï¼Ÿ")
        st.info("2. **è¯Šæ–­æŸ¥è¯¢**: è¯·é—®å¦‚ä½•æŸ¥è¯¢æ•…éšœç”µå¼§å‘ç”Ÿçš„æ ¹æœ¬åŸå› ï¼Œä»¥åŠèˆ¹çº§ç¤¾çš„ç»´æŠ¤è¦æ±‚ï¼Ÿ")
        st.info("3. **ç³»ç»ŸçŠ¶æ€**: è¯·å‘ŠçŸ¥æˆ‘è¾¹ç¼˜è®¡ç®—å•å…ƒçš„è´Ÿè½½ç‡å’Œç³»ç»Ÿç¨³å®šæ€§å¦‚ä½•ï¼Ÿ")

        # èŠå¤©è¾“å…¥å¤„ç†
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # ç”Ÿæˆæ™ºèƒ½ä½“å“åº”
            with st.chat_message("assistant"):
                current_status = status_text
                response = intelligent_agent_response(prompt, current_status)
                # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ
                full_response = ""
                message_placeholder = st.empty()
                for chunk in response.split():
                    full_response += chunk + " "
                    time.sleep(0.02)
                    message_placeholder.markdown(full_response + "â–Œ")
                message_placeholder.markdown(full_response)
            # ä¿å­˜æ™ºèƒ½ä½“å“åº”
            st.session_state.messages.append({"role": "assistant", "content": response})



if __name__ == "__main__":
    main()
